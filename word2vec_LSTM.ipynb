{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec_ML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZqNzm6vEul2"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueCKZhOhFHlr"
      },
      "source": [
        "data=pd.read_csv('/content/preprocessed_ade.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "_drP0Ym9F32U",
        "outputId": "ccee8a45-2782-47a4-e696-c951b30b7590"
      },
      "source": [
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>observation</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12606</td>\n",
              "      <td>early phase ii semi double blind study of the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>685</td>\n",
              "      <td>cessation of mtx therapy led to complete regre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5127</td>\n",
              "      <td>cutaneous biopsy showed hyphae and round inclu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3158</td>\n",
              "      <td>she was treated with acyclovir and subsequentl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10685</td>\n",
              "      <td>cisplatin was substituted and the patient achi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23511</th>\n",
              "      <td>982</td>\n",
              "      <td>ticlopidine induced aplastic anemia  two new c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23512</th>\n",
              "      <td>14487</td>\n",
              "      <td>the risks of sumatriptan administration in pat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23513</th>\n",
              "      <td>4680</td>\n",
              "      <td>however   the spectrum of hosts and clinical p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23514</th>\n",
              "      <td>2588</td>\n",
              "      <td>antibiotic treatment should be continued</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23515</th>\n",
              "      <td>6571</td>\n",
              "      <td>in case     a total daily dose of    mg sertra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23516 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                                        observation  labels\n",
              "0           12606  early phase ii semi double blind study of the ...       0\n",
              "1             685  cessation of mtx therapy led to complete regre...       0\n",
              "2            5127  cutaneous biopsy showed hyphae and round inclu...       0\n",
              "3            3158  she was treated with acyclovir and subsequentl...       1\n",
              "4           10685  cisplatin was substituted and the patient achi...       0\n",
              "...           ...                                                ...     ...\n",
              "23511         982  ticlopidine induced aplastic anemia  two new c...       1\n",
              "23512       14487  the risks of sumatriptan administration in pat...       0\n",
              "23513        4680  however   the spectrum of hosts and clinical p...       0\n",
              "23514        2588           antibiotic treatment should be continued       0\n",
              "23515        6571  in case     a total daily dose of    mg sertra...       1\n",
              "\n",
              "[23516 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFFGDoTeF45v"
      },
      "source": [
        "import gensim\n",
        "import os\n",
        "import nltk"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW8vYTmyGCFa",
        "outputId": "97d119d8-a76f-49ea-e772-6beebad8deec"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiYPtizvGRBy",
        "outputId": "b22032a4-fbc2-48c8-ca8b-3d9b3fca5bcb"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkCesugdGTsk"
      },
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "E-2EzJz_GkqS",
        "outputId": "599dc289-6e7d-46d1-f900-6f068f108a58"
      },
      "source": [
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>observation</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12606</td>\n",
              "      <td>early phase ii semi double blind study of the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>685</td>\n",
              "      <td>cessation of mtx therapy led to complete regre...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5127</td>\n",
              "      <td>cutaneous biopsy showed hyphae and round inclu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3158</td>\n",
              "      <td>she was treated with acyclovir and subsequentl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10685</td>\n",
              "      <td>cisplatin was substituted and the patient achi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23511</th>\n",
              "      <td>982</td>\n",
              "      <td>ticlopidine induced aplastic anemia  two new c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23512</th>\n",
              "      <td>14487</td>\n",
              "      <td>the risks of sumatriptan administration in pat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23513</th>\n",
              "      <td>4680</td>\n",
              "      <td>however   the spectrum of hosts and clinical p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23514</th>\n",
              "      <td>2588</td>\n",
              "      <td>antibiotic treatment should be continued</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23515</th>\n",
              "      <td>6571</td>\n",
              "      <td>in case     a total daily dose of    mg sertra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23516 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                                        observation  labels\n",
              "0           12606  early phase ii semi double blind study of the ...       0\n",
              "1             685  cessation of mtx therapy led to complete regre...       0\n",
              "2            5127  cutaneous biopsy showed hyphae and round inclu...       0\n",
              "3            3158  she was treated with acyclovir and subsequentl...       1\n",
              "4           10685  cisplatin was substituted and the patient achi...       0\n",
              "...           ...                                                ...     ...\n",
              "23511         982  ticlopidine induced aplastic anemia  two new c...       1\n",
              "23512       14487  the risks of sumatriptan administration in pat...       0\n",
              "23513        4680  however   the spectrum of hosts and clinical p...       0\n",
              "23514        2588           antibiotic treatment should be continued       0\n",
              "23515        6571  in case     a total daily dose of    mg sertra...       1\n",
              "\n",
              "[23516 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgDzvYcaG_Uq",
        "outputId": "c4d3372b-080e-41f6-e978-1f4986fc04cc"
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-26 13:18:31--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.202.160\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.202.160|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: â€˜/root/input/GoogleNews-vectors-negative300.bin.gzâ€™\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  84.5MB/s    in 25s     \n",
            "\n",
            "2021-06-26 13:18:56 (62.8 MB/s) - â€˜/root/input/GoogleNews-vectors-negative300.bin.gzâ€™ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s01ESftHNcm"
      },
      "source": [
        "url=\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JMc-0QFHm3t"
      },
      "source": [
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(url, binary=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlUREQiHHqb_",
        "outputId": "6e3962a3-38cd-4886-b118-ef5262f0dcc1"
      },
      "source": [
        "docs_vectors = pd.DataFrame() # creating empty final dataframe\n",
        "stopwords = nltk.corpus.stopwords.words('english') # removing stop words\n",
        "for doc in data['observation'].str.lower().str.replace('[^a-z ]', ''): # looping through each document and cleaning it\n",
        "    temp = pd.DataFrame()  # creating a temporary dataframe(store value for 1st doc & for 2nd doc remove the details of 1st & proced through 2nd and so on..)\n",
        "    for word in doc.split(' '): # looping through each word of a single document and spliting through space\n",
        "        if word not in stopwords: # if word is not present in stopwords then (try)\n",
        "            try:\n",
        "                word_vec = embeddings[word] # if word is present in embeddings(goole provides weights associate with words(300)) then proceed\n",
        "                temp = temp.append(pd.Series(word_vec), ignore_index = True) # if word is present then append it to temporary dataframe\n",
        "            except:\n",
        "                pass\n",
        "    doc_vector = temp.mean() # take the average of each column(w0, w1, w2,........w300)\n",
        "    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) # append each document value to the final dataframe\n",
        "docs_vectors.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23516, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_GHc7yjKC70"
      },
      "source": [
        " docs_vectors['labels'] = data['labels']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtC7wVxUS2bT"
      },
      "source": [
        "docs_vectors = docs_vectors.dropna()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "hI0fLFw8P3Cs",
        "outputId": "760248dc-d8f7-47f1-c133-a4acfd73a09a"
      },
      "source": [
        "docs_vectors"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.050695</td>\n",
              "      <td>-0.013357</td>\n",
              "      <td>-0.008664</td>\n",
              "      <td>0.066528</td>\n",
              "      <td>-0.052307</td>\n",
              "      <td>-0.042175</td>\n",
              "      <td>0.077194</td>\n",
              "      <td>-0.106771</td>\n",
              "      <td>0.094014</td>\n",
              "      <td>0.025045</td>\n",
              "      <td>-0.002279</td>\n",
              "      <td>-0.073015</td>\n",
              "      <td>-0.062754</td>\n",
              "      <td>0.023458</td>\n",
              "      <td>-0.113424</td>\n",
              "      <td>0.005196</td>\n",
              "      <td>-0.003326</td>\n",
              "      <td>0.046899</td>\n",
              "      <td>0.092621</td>\n",
              "      <td>-0.086620</td>\n",
              "      <td>-0.030538</td>\n",
              "      <td>-0.061499</td>\n",
              "      <td>-0.107239</td>\n",
              "      <td>-0.073883</td>\n",
              "      <td>-0.008952</td>\n",
              "      <td>0.003123</td>\n",
              "      <td>-0.046076</td>\n",
              "      <td>0.072083</td>\n",
              "      <td>0.063965</td>\n",
              "      <td>0.034098</td>\n",
              "      <td>-0.001490</td>\n",
              "      <td>-0.015025</td>\n",
              "      <td>0.024556</td>\n",
              "      <td>-0.051412</td>\n",
              "      <td>-0.079405</td>\n",
              "      <td>-0.059469</td>\n",
              "      <td>0.018873</td>\n",
              "      <td>-0.052607</td>\n",
              "      <td>0.112142</td>\n",
              "      <td>-0.071477</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039042</td>\n",
              "      <td>-0.066981</td>\n",
              "      <td>0.039108</td>\n",
              "      <td>0.031909</td>\n",
              "      <td>0.104273</td>\n",
              "      <td>-0.026176</td>\n",
              "      <td>-0.130332</td>\n",
              "      <td>-0.123133</td>\n",
              "      <td>0.029694</td>\n",
              "      <td>0.054385</td>\n",
              "      <td>0.017690</td>\n",
              "      <td>0.007355</td>\n",
              "      <td>-0.070262</td>\n",
              "      <td>0.055140</td>\n",
              "      <td>0.007670</td>\n",
              "      <td>-0.037689</td>\n",
              "      <td>-0.070933</td>\n",
              "      <td>-0.019201</td>\n",
              "      <td>0.056788</td>\n",
              "      <td>0.044965</td>\n",
              "      <td>0.039923</td>\n",
              "      <td>0.023499</td>\n",
              "      <td>0.012102</td>\n",
              "      <td>0.052272</td>\n",
              "      <td>-0.067769</td>\n",
              "      <td>0.005969</td>\n",
              "      <td>-0.063703</td>\n",
              "      <td>0.014497</td>\n",
              "      <td>0.013255</td>\n",
              "      <td>-0.005880</td>\n",
              "      <td>0.069450</td>\n",
              "      <td>-0.066691</td>\n",
              "      <td>-0.055615</td>\n",
              "      <td>-0.068281</td>\n",
              "      <td>-0.005549</td>\n",
              "      <td>-0.106692</td>\n",
              "      <td>0.031687</td>\n",
              "      <td>-0.025411</td>\n",
              "      <td>0.035197</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.003021</td>\n",
              "      <td>0.127523</td>\n",
              "      <td>0.022970</td>\n",
              "      <td>0.078756</td>\n",
              "      <td>-0.108480</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>-0.025464</td>\n",
              "      <td>-0.258464</td>\n",
              "      <td>0.102407</td>\n",
              "      <td>-0.010974</td>\n",
              "      <td>-0.041590</td>\n",
              "      <td>-0.183228</td>\n",
              "      <td>0.019145</td>\n",
              "      <td>0.065308</td>\n",
              "      <td>0.030192</td>\n",
              "      <td>0.245097</td>\n",
              "      <td>0.080068</td>\n",
              "      <td>-0.014318</td>\n",
              "      <td>0.003296</td>\n",
              "      <td>-0.170492</td>\n",
              "      <td>0.016622</td>\n",
              "      <td>0.125977</td>\n",
              "      <td>-0.055054</td>\n",
              "      <td>0.191996</td>\n",
              "      <td>-0.136230</td>\n",
              "      <td>0.046834</td>\n",
              "      <td>-0.257161</td>\n",
              "      <td>-0.001546</td>\n",
              "      <td>0.073795</td>\n",
              "      <td>-0.008087</td>\n",
              "      <td>0.038411</td>\n",
              "      <td>-0.253988</td>\n",
              "      <td>-0.172902</td>\n",
              "      <td>0.072103</td>\n",
              "      <td>-0.274129</td>\n",
              "      <td>-0.037720</td>\n",
              "      <td>-0.071818</td>\n",
              "      <td>-0.001750</td>\n",
              "      <td>0.019694</td>\n",
              "      <td>-0.058512</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023560</td>\n",
              "      <td>-0.005086</td>\n",
              "      <td>-0.016195</td>\n",
              "      <td>0.122925</td>\n",
              "      <td>0.153564</td>\n",
              "      <td>0.092306</td>\n",
              "      <td>-0.107666</td>\n",
              "      <td>-0.094686</td>\n",
              "      <td>-0.038452</td>\n",
              "      <td>0.129679</td>\n",
              "      <td>0.189931</td>\n",
              "      <td>-0.090637</td>\n",
              "      <td>-0.015818</td>\n",
              "      <td>0.167480</td>\n",
              "      <td>0.069153</td>\n",
              "      <td>-0.120809</td>\n",
              "      <td>0.080282</td>\n",
              "      <td>0.039800</td>\n",
              "      <td>0.011545</td>\n",
              "      <td>0.092285</td>\n",
              "      <td>0.134562</td>\n",
              "      <td>0.054606</td>\n",
              "      <td>-0.062337</td>\n",
              "      <td>-0.047445</td>\n",
              "      <td>-0.135681</td>\n",
              "      <td>0.168050</td>\n",
              "      <td>0.019450</td>\n",
              "      <td>0.060410</td>\n",
              "      <td>-0.014730</td>\n",
              "      <td>-0.113851</td>\n",
              "      <td>0.076541</td>\n",
              "      <td>0.077482</td>\n",
              "      <td>-0.045329</td>\n",
              "      <td>-0.001383</td>\n",
              "      <td>-0.022359</td>\n",
              "      <td>-0.056244</td>\n",
              "      <td>0.130605</td>\n",
              "      <td>0.129150</td>\n",
              "      <td>0.039032</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.029696</td>\n",
              "      <td>0.117454</td>\n",
              "      <td>0.070279</td>\n",
              "      <td>0.049297</td>\n",
              "      <td>-0.143677</td>\n",
              "      <td>0.020880</td>\n",
              "      <td>-0.034909</td>\n",
              "      <td>-0.225763</td>\n",
              "      <td>0.071650</td>\n",
              "      <td>0.107422</td>\n",
              "      <td>-0.133434</td>\n",
              "      <td>-0.185225</td>\n",
              "      <td>-0.064337</td>\n",
              "      <td>0.098145</td>\n",
              "      <td>-0.072820</td>\n",
              "      <td>0.187689</td>\n",
              "      <td>0.063008</td>\n",
              "      <td>0.230735</td>\n",
              "      <td>-0.073231</td>\n",
              "      <td>0.010345</td>\n",
              "      <td>-0.069647</td>\n",
              "      <td>-0.056596</td>\n",
              "      <td>-0.062522</td>\n",
              "      <td>0.020130</td>\n",
              "      <td>-0.188754</td>\n",
              "      <td>-0.137140</td>\n",
              "      <td>-0.148304</td>\n",
              "      <td>0.077767</td>\n",
              "      <td>-0.025036</td>\n",
              "      <td>-0.118508</td>\n",
              "      <td>-0.092396</td>\n",
              "      <td>0.002475</td>\n",
              "      <td>0.010717</td>\n",
              "      <td>-0.007025</td>\n",
              "      <td>-0.138278</td>\n",
              "      <td>0.005085</td>\n",
              "      <td>0.043518</td>\n",
              "      <td>0.064731</td>\n",
              "      <td>0.043790</td>\n",
              "      <td>0.038613</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048273</td>\n",
              "      <td>-0.010312</td>\n",
              "      <td>-0.112371</td>\n",
              "      <td>0.046531</td>\n",
              "      <td>0.120449</td>\n",
              "      <td>0.060059</td>\n",
              "      <td>-0.127644</td>\n",
              "      <td>0.040558</td>\n",
              "      <td>-0.075150</td>\n",
              "      <td>-0.036205</td>\n",
              "      <td>0.173329</td>\n",
              "      <td>-0.076527</td>\n",
              "      <td>-0.005085</td>\n",
              "      <td>0.192204</td>\n",
              "      <td>-0.018815</td>\n",
              "      <td>-0.092661</td>\n",
              "      <td>0.006947</td>\n",
              "      <td>0.019054</td>\n",
              "      <td>0.138184</td>\n",
              "      <td>0.096868</td>\n",
              "      <td>0.022367</td>\n",
              "      <td>0.050756</td>\n",
              "      <td>-0.051164</td>\n",
              "      <td>-0.029707</td>\n",
              "      <td>-0.083724</td>\n",
              "      <td>0.039218</td>\n",
              "      <td>-0.012851</td>\n",
              "      <td>-0.146107</td>\n",
              "      <td>0.018256</td>\n",
              "      <td>-0.018488</td>\n",
              "      <td>-0.023948</td>\n",
              "      <td>0.089930</td>\n",
              "      <td>0.033869</td>\n",
              "      <td>-0.042969</td>\n",
              "      <td>0.057861</td>\n",
              "      <td>-0.091569</td>\n",
              "      <td>-0.049128</td>\n",
              "      <td>0.084306</td>\n",
              "      <td>0.066426</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.034995</td>\n",
              "      <td>0.044120</td>\n",
              "      <td>0.062256</td>\n",
              "      <td>0.079346</td>\n",
              "      <td>-0.163993</td>\n",
              "      <td>-0.040091</td>\n",
              "      <td>-0.057486</td>\n",
              "      <td>-0.120919</td>\n",
              "      <td>0.014265</td>\n",
              "      <td>0.075091</td>\n",
              "      <td>-0.192383</td>\n",
              "      <td>-0.232945</td>\n",
              "      <td>0.041138</td>\n",
              "      <td>0.021345</td>\n",
              "      <td>-0.151341</td>\n",
              "      <td>0.085903</td>\n",
              "      <td>-0.082441</td>\n",
              "      <td>0.236258</td>\n",
              "      <td>0.020050</td>\n",
              "      <td>0.091936</td>\n",
              "      <td>0.004220</td>\n",
              "      <td>0.075405</td>\n",
              "      <td>0.031786</td>\n",
              "      <td>-0.028285</td>\n",
              "      <td>-0.077676</td>\n",
              "      <td>-0.140102</td>\n",
              "      <td>-0.061558</td>\n",
              "      <td>0.049909</td>\n",
              "      <td>-0.002860</td>\n",
              "      <td>0.038225</td>\n",
              "      <td>-0.122105</td>\n",
              "      <td>-0.236049</td>\n",
              "      <td>-0.023071</td>\n",
              "      <td>0.013157</td>\n",
              "      <td>-0.068324</td>\n",
              "      <td>0.045576</td>\n",
              "      <td>0.005197</td>\n",
              "      <td>0.019531</td>\n",
              "      <td>-0.029465</td>\n",
              "      <td>-0.038295</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009234</td>\n",
              "      <td>-0.005153</td>\n",
              "      <td>-0.133806</td>\n",
              "      <td>0.153460</td>\n",
              "      <td>0.087899</td>\n",
              "      <td>0.072405</td>\n",
              "      <td>-0.104771</td>\n",
              "      <td>-0.013811</td>\n",
              "      <td>0.003383</td>\n",
              "      <td>0.105730</td>\n",
              "      <td>0.146362</td>\n",
              "      <td>-0.050642</td>\n",
              "      <td>-0.025257</td>\n",
              "      <td>0.165414</td>\n",
              "      <td>-0.028983</td>\n",
              "      <td>-0.061070</td>\n",
              "      <td>0.136161</td>\n",
              "      <td>0.002921</td>\n",
              "      <td>0.026228</td>\n",
              "      <td>-0.047032</td>\n",
              "      <td>0.073661</td>\n",
              "      <td>0.012591</td>\n",
              "      <td>-0.096392</td>\n",
              "      <td>-0.066232</td>\n",
              "      <td>-0.169316</td>\n",
              "      <td>0.125610</td>\n",
              "      <td>0.111904</td>\n",
              "      <td>-0.083758</td>\n",
              "      <td>0.105756</td>\n",
              "      <td>-0.125488</td>\n",
              "      <td>0.016497</td>\n",
              "      <td>-0.001325</td>\n",
              "      <td>0.106097</td>\n",
              "      <td>0.092913</td>\n",
              "      <td>0.194301</td>\n",
              "      <td>-0.168597</td>\n",
              "      <td>0.067226</td>\n",
              "      <td>0.183340</td>\n",
              "      <td>-0.034546</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.015993</td>\n",
              "      <td>0.063070</td>\n",
              "      <td>-0.002374</td>\n",
              "      <td>0.145820</td>\n",
              "      <td>-0.082438</td>\n",
              "      <td>0.000461</td>\n",
              "      <td>0.064053</td>\n",
              "      <td>-0.192383</td>\n",
              "      <td>0.125637</td>\n",
              "      <td>0.018826</td>\n",
              "      <td>-0.172716</td>\n",
              "      <td>-0.213867</td>\n",
              "      <td>0.005659</td>\n",
              "      <td>0.001294</td>\n",
              "      <td>0.017849</td>\n",
              "      <td>0.249525</td>\n",
              "      <td>0.088019</td>\n",
              "      <td>0.018311</td>\n",
              "      <td>-0.027913</td>\n",
              "      <td>-0.134142</td>\n",
              "      <td>0.034424</td>\n",
              "      <td>0.093031</td>\n",
              "      <td>-0.089423</td>\n",
              "      <td>0.083279</td>\n",
              "      <td>-0.061584</td>\n",
              "      <td>-0.042616</td>\n",
              "      <td>-0.188856</td>\n",
              "      <td>-0.040602</td>\n",
              "      <td>0.014445</td>\n",
              "      <td>0.056342</td>\n",
              "      <td>0.032718</td>\n",
              "      <td>-0.126126</td>\n",
              "      <td>-0.226671</td>\n",
              "      <td>-0.081546</td>\n",
              "      <td>-0.199599</td>\n",
              "      <td>-0.025684</td>\n",
              "      <td>0.005062</td>\n",
              "      <td>0.018643</td>\n",
              "      <td>0.045939</td>\n",
              "      <td>-0.028630</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.041456</td>\n",
              "      <td>-0.042101</td>\n",
              "      <td>-0.080397</td>\n",
              "      <td>0.130995</td>\n",
              "      <td>0.052138</td>\n",
              "      <td>0.089925</td>\n",
              "      <td>-0.214205</td>\n",
              "      <td>-0.121718</td>\n",
              "      <td>-0.065077</td>\n",
              "      <td>0.069255</td>\n",
              "      <td>0.155545</td>\n",
              "      <td>-0.040944</td>\n",
              "      <td>0.047689</td>\n",
              "      <td>0.095893</td>\n",
              "      <td>-0.055393</td>\n",
              "      <td>-0.195258</td>\n",
              "      <td>-0.037672</td>\n",
              "      <td>0.029673</td>\n",
              "      <td>0.011854</td>\n",
              "      <td>0.120734</td>\n",
              "      <td>0.132958</td>\n",
              "      <td>-0.021444</td>\n",
              "      <td>-0.061561</td>\n",
              "      <td>-0.047670</td>\n",
              "      <td>-0.111681</td>\n",
              "      <td>0.130615</td>\n",
              "      <td>-0.031660</td>\n",
              "      <td>0.005324</td>\n",
              "      <td>0.039551</td>\n",
              "      <td>-0.141086</td>\n",
              "      <td>0.047343</td>\n",
              "      <td>0.018546</td>\n",
              "      <td>0.111294</td>\n",
              "      <td>-0.011664</td>\n",
              "      <td>0.049018</td>\n",
              "      <td>-0.085734</td>\n",
              "      <td>0.107395</td>\n",
              "      <td>0.117784</td>\n",
              "      <td>0.017456</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23511</th>\n",
              "      <td>-0.037612</td>\n",
              "      <td>-0.003371</td>\n",
              "      <td>-0.043265</td>\n",
              "      <td>0.060829</td>\n",
              "      <td>-0.077900</td>\n",
              "      <td>0.035510</td>\n",
              "      <td>0.062455</td>\n",
              "      <td>-0.100464</td>\n",
              "      <td>0.101638</td>\n",
              "      <td>0.018494</td>\n",
              "      <td>-0.090628</td>\n",
              "      <td>-0.073918</td>\n",
              "      <td>-0.000499</td>\n",
              "      <td>0.056472</td>\n",
              "      <td>-0.130061</td>\n",
              "      <td>0.071543</td>\n",
              "      <td>-0.024954</td>\n",
              "      <td>0.068062</td>\n",
              "      <td>-0.116436</td>\n",
              "      <td>-0.070378</td>\n",
              "      <td>0.042861</td>\n",
              "      <td>-0.054393</td>\n",
              "      <td>-0.105666</td>\n",
              "      <td>-0.012996</td>\n",
              "      <td>-0.020193</td>\n",
              "      <td>-0.019555</td>\n",
              "      <td>-0.028226</td>\n",
              "      <td>0.068575</td>\n",
              "      <td>-0.059411</td>\n",
              "      <td>0.009813</td>\n",
              "      <td>-0.007258</td>\n",
              "      <td>-0.090210</td>\n",
              "      <td>-0.007754</td>\n",
              "      <td>-0.038959</td>\n",
              "      <td>-0.091341</td>\n",
              "      <td>-0.028813</td>\n",
              "      <td>-0.004066</td>\n",
              "      <td>-0.056622</td>\n",
              "      <td>0.083790</td>\n",
              "      <td>0.003812</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049697</td>\n",
              "      <td>-0.048626</td>\n",
              "      <td>0.013390</td>\n",
              "      <td>0.017353</td>\n",
              "      <td>0.063120</td>\n",
              "      <td>-0.060248</td>\n",
              "      <td>0.005474</td>\n",
              "      <td>-0.074578</td>\n",
              "      <td>-0.061257</td>\n",
              "      <td>0.110971</td>\n",
              "      <td>0.140644</td>\n",
              "      <td>0.027607</td>\n",
              "      <td>-0.037203</td>\n",
              "      <td>0.095501</td>\n",
              "      <td>0.039283</td>\n",
              "      <td>-0.026846</td>\n",
              "      <td>-0.035515</td>\n",
              "      <td>0.077969</td>\n",
              "      <td>0.032222</td>\n",
              "      <td>-0.074379</td>\n",
              "      <td>0.016733</td>\n",
              "      <td>-0.009831</td>\n",
              "      <td>-0.007709</td>\n",
              "      <td>-0.013878</td>\n",
              "      <td>-0.067721</td>\n",
              "      <td>0.026790</td>\n",
              "      <td>0.050683</td>\n",
              "      <td>0.044800</td>\n",
              "      <td>0.008489</td>\n",
              "      <td>0.022705</td>\n",
              "      <td>-0.045044</td>\n",
              "      <td>0.041720</td>\n",
              "      <td>0.073773</td>\n",
              "      <td>-0.018536</td>\n",
              "      <td>0.036471</td>\n",
              "      <td>-0.045362</td>\n",
              "      <td>-0.050205</td>\n",
              "      <td>0.091285</td>\n",
              "      <td>0.045650</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23512</th>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.071014</td>\n",
              "      <td>-0.004820</td>\n",
              "      <td>0.158752</td>\n",
              "      <td>-0.061707</td>\n",
              "      <td>-0.020960</td>\n",
              "      <td>-0.036949</td>\n",
              "      <td>-0.118683</td>\n",
              "      <td>0.126301</td>\n",
              "      <td>-0.060120</td>\n",
              "      <td>-0.075760</td>\n",
              "      <td>-0.186272</td>\n",
              "      <td>-0.123383</td>\n",
              "      <td>0.173462</td>\n",
              "      <td>-0.051178</td>\n",
              "      <td>0.162476</td>\n",
              "      <td>-0.064240</td>\n",
              "      <td>0.039627</td>\n",
              "      <td>-0.009872</td>\n",
              "      <td>-0.049927</td>\n",
              "      <td>-0.024487</td>\n",
              "      <td>-0.049332</td>\n",
              "      <td>0.093262</td>\n",
              "      <td>0.040314</td>\n",
              "      <td>-0.090790</td>\n",
              "      <td>-0.028717</td>\n",
              "      <td>-0.104034</td>\n",
              "      <td>-0.028282</td>\n",
              "      <td>-0.030167</td>\n",
              "      <td>-0.084167</td>\n",
              "      <td>-0.009079</td>\n",
              "      <td>-0.083191</td>\n",
              "      <td>-0.041458</td>\n",
              "      <td>-0.034035</td>\n",
              "      <td>-0.185638</td>\n",
              "      <td>-0.092236</td>\n",
              "      <td>0.017303</td>\n",
              "      <td>0.007244</td>\n",
              "      <td>-0.005356</td>\n",
              "      <td>-0.014282</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050598</td>\n",
              "      <td>0.068748</td>\n",
              "      <td>-0.061462</td>\n",
              "      <td>-0.153748</td>\n",
              "      <td>0.098999</td>\n",
              "      <td>-0.008041</td>\n",
              "      <td>-0.091873</td>\n",
              "      <td>-0.082703</td>\n",
              "      <td>-0.195190</td>\n",
              "      <td>-0.041576</td>\n",
              "      <td>0.056549</td>\n",
              "      <td>0.027466</td>\n",
              "      <td>-0.085241</td>\n",
              "      <td>0.087189</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>-0.050431</td>\n",
              "      <td>0.054474</td>\n",
              "      <td>0.002136</td>\n",
              "      <td>0.006409</td>\n",
              "      <td>-0.050631</td>\n",
              "      <td>0.066696</td>\n",
              "      <td>-0.021244</td>\n",
              "      <td>-0.066956</td>\n",
              "      <td>-0.000626</td>\n",
              "      <td>-0.064774</td>\n",
              "      <td>0.066849</td>\n",
              "      <td>-0.002258</td>\n",
              "      <td>0.058861</td>\n",
              "      <td>0.041109</td>\n",
              "      <td>0.101761</td>\n",
              "      <td>-0.040702</td>\n",
              "      <td>0.004974</td>\n",
              "      <td>-0.019695</td>\n",
              "      <td>-0.137497</td>\n",
              "      <td>0.171402</td>\n",
              "      <td>-0.036266</td>\n",
              "      <td>0.147522</td>\n",
              "      <td>0.142891</td>\n",
              "      <td>0.104774</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23513</th>\n",
              "      <td>-0.051111</td>\n",
              "      <td>0.146917</td>\n",
              "      <td>-0.019682</td>\n",
              "      <td>0.086093</td>\n",
              "      <td>-0.102982</td>\n",
              "      <td>0.056725</td>\n",
              "      <td>0.080206</td>\n",
              "      <td>-0.114224</td>\n",
              "      <td>0.084534</td>\n",
              "      <td>-0.022417</td>\n",
              "      <td>-0.084183</td>\n",
              "      <td>-0.182635</td>\n",
              "      <td>-0.009181</td>\n",
              "      <td>0.108895</td>\n",
              "      <td>-0.036973</td>\n",
              "      <td>0.093502</td>\n",
              "      <td>0.032000</td>\n",
              "      <td>0.123628</td>\n",
              "      <td>-0.016803</td>\n",
              "      <td>0.029843</td>\n",
              "      <td>0.030721</td>\n",
              "      <td>-0.023426</td>\n",
              "      <td>0.011954</td>\n",
              "      <td>0.076741</td>\n",
              "      <td>-0.078477</td>\n",
              "      <td>-0.049872</td>\n",
              "      <td>-0.148042</td>\n",
              "      <td>-0.023638</td>\n",
              "      <td>-0.030293</td>\n",
              "      <td>-0.061593</td>\n",
              "      <td>-0.040818</td>\n",
              "      <td>-0.059878</td>\n",
              "      <td>-0.044519</td>\n",
              "      <td>-0.054693</td>\n",
              "      <td>-0.088408</td>\n",
              "      <td>-0.021659</td>\n",
              "      <td>-0.022339</td>\n",
              "      <td>0.042212</td>\n",
              "      <td>0.047070</td>\n",
              "      <td>0.003325</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002157</td>\n",
              "      <td>-0.003417</td>\n",
              "      <td>0.001617</td>\n",
              "      <td>0.042870</td>\n",
              "      <td>0.062366</td>\n",
              "      <td>-0.082857</td>\n",
              "      <td>-0.038144</td>\n",
              "      <td>-0.105296</td>\n",
              "      <td>-0.082960</td>\n",
              "      <td>0.028753</td>\n",
              "      <td>0.109869</td>\n",
              "      <td>0.027820</td>\n",
              "      <td>-0.061951</td>\n",
              "      <td>0.118007</td>\n",
              "      <td>-0.057885</td>\n",
              "      <td>-0.050414</td>\n",
              "      <td>0.051653</td>\n",
              "      <td>0.004143</td>\n",
              "      <td>0.040027</td>\n",
              "      <td>0.095886</td>\n",
              "      <td>0.021422</td>\n",
              "      <td>0.062185</td>\n",
              "      <td>-0.017383</td>\n",
              "      <td>-0.054121</td>\n",
              "      <td>-0.044428</td>\n",
              "      <td>0.125668</td>\n",
              "      <td>-0.024727</td>\n",
              "      <td>0.034831</td>\n",
              "      <td>0.041553</td>\n",
              "      <td>-0.026454</td>\n",
              "      <td>-0.027222</td>\n",
              "      <td>-0.117949</td>\n",
              "      <td>0.084025</td>\n",
              "      <td>0.019043</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>-0.073184</td>\n",
              "      <td>0.052422</td>\n",
              "      <td>0.156669</td>\n",
              "      <td>0.086036</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23514</th>\n",
              "      <td>-0.108724</td>\n",
              "      <td>0.262695</td>\n",
              "      <td>-0.012207</td>\n",
              "      <td>0.074382</td>\n",
              "      <td>-0.040365</td>\n",
              "      <td>-0.028483</td>\n",
              "      <td>0.034922</td>\n",
              "      <td>-0.249512</td>\n",
              "      <td>0.019938</td>\n",
              "      <td>-0.072754</td>\n",
              "      <td>-0.196289</td>\n",
              "      <td>-0.247152</td>\n",
              "      <td>0.075195</td>\n",
              "      <td>0.076823</td>\n",
              "      <td>-0.074992</td>\n",
              "      <td>0.036133</td>\n",
              "      <td>-0.075439</td>\n",
              "      <td>0.119100</td>\n",
              "      <td>0.005981</td>\n",
              "      <td>-0.003845</td>\n",
              "      <td>0.086589</td>\n",
              "      <td>0.103841</td>\n",
              "      <td>0.184652</td>\n",
              "      <td>0.119751</td>\n",
              "      <td>-0.164632</td>\n",
              "      <td>-0.128581</td>\n",
              "      <td>-0.036051</td>\n",
              "      <td>0.057780</td>\n",
              "      <td>-0.029948</td>\n",
              "      <td>0.071615</td>\n",
              "      <td>-0.047201</td>\n",
              "      <td>-0.165649</td>\n",
              "      <td>-0.134033</td>\n",
              "      <td>-0.062988</td>\n",
              "      <td>-0.182170</td>\n",
              "      <td>0.217448</td>\n",
              "      <td>0.069132</td>\n",
              "      <td>-0.006002</td>\n",
              "      <td>0.068166</td>\n",
              "      <td>-0.078451</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007568</td>\n",
              "      <td>-0.069173</td>\n",
              "      <td>0.050008</td>\n",
              "      <td>0.190104</td>\n",
              "      <td>0.047445</td>\n",
              "      <td>-0.009481</td>\n",
              "      <td>-0.184408</td>\n",
              "      <td>-0.088877</td>\n",
              "      <td>0.006144</td>\n",
              "      <td>0.107056</td>\n",
              "      <td>0.135986</td>\n",
              "      <td>-0.066895</td>\n",
              "      <td>-0.112956</td>\n",
              "      <td>0.175944</td>\n",
              "      <td>-0.055013</td>\n",
              "      <td>-0.179688</td>\n",
              "      <td>0.053935</td>\n",
              "      <td>0.150675</td>\n",
              "      <td>0.130371</td>\n",
              "      <td>0.144694</td>\n",
              "      <td>0.066650</td>\n",
              "      <td>0.158366</td>\n",
              "      <td>-0.031413</td>\n",
              "      <td>-0.146484</td>\n",
              "      <td>0.059733</td>\n",
              "      <td>0.159831</td>\n",
              "      <td>0.260864</td>\n",
              "      <td>0.099935</td>\n",
              "      <td>0.015137</td>\n",
              "      <td>-0.115316</td>\n",
              "      <td>-0.007202</td>\n",
              "      <td>-0.097331</td>\n",
              "      <td>0.163900</td>\n",
              "      <td>-0.006063</td>\n",
              "      <td>0.100586</td>\n",
              "      <td>-0.055339</td>\n",
              "      <td>0.288737</td>\n",
              "      <td>0.284668</td>\n",
              "      <td>0.115234</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23515</th>\n",
              "      <td>-0.116017</td>\n",
              "      <td>0.087541</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>0.116304</td>\n",
              "      <td>0.016904</td>\n",
              "      <td>0.007917</td>\n",
              "      <td>0.096838</td>\n",
              "      <td>-0.138991</td>\n",
              "      <td>0.137035</td>\n",
              "      <td>0.105365</td>\n",
              "      <td>-0.013352</td>\n",
              "      <td>-0.147637</td>\n",
              "      <td>0.054386</td>\n",
              "      <td>0.113662</td>\n",
              "      <td>-0.123009</td>\n",
              "      <td>0.071120</td>\n",
              "      <td>-0.107758</td>\n",
              "      <td>0.072343</td>\n",
              "      <td>0.037081</td>\n",
              "      <td>-0.120792</td>\n",
              "      <td>-0.022685</td>\n",
              "      <td>-0.098615</td>\n",
              "      <td>-0.031587</td>\n",
              "      <td>-0.045063</td>\n",
              "      <td>-0.103085</td>\n",
              "      <td>-0.085579</td>\n",
              "      <td>-0.158118</td>\n",
              "      <td>0.122343</td>\n",
              "      <td>-0.070725</td>\n",
              "      <td>-0.031710</td>\n",
              "      <td>-0.000273</td>\n",
              "      <td>-0.077206</td>\n",
              "      <td>-0.054944</td>\n",
              "      <td>-0.035329</td>\n",
              "      <td>-0.288280</td>\n",
              "      <td>-0.102636</td>\n",
              "      <td>0.008314</td>\n",
              "      <td>-0.034546</td>\n",
              "      <td>-0.000381</td>\n",
              "      <td>0.056484</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005105</td>\n",
              "      <td>0.043542</td>\n",
              "      <td>-0.133130</td>\n",
              "      <td>0.067972</td>\n",
              "      <td>0.137509</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>-0.101261</td>\n",
              "      <td>0.014630</td>\n",
              "      <td>-0.157986</td>\n",
              "      <td>0.018892</td>\n",
              "      <td>0.166784</td>\n",
              "      <td>-0.033469</td>\n",
              "      <td>0.005773</td>\n",
              "      <td>0.085596</td>\n",
              "      <td>0.039389</td>\n",
              "      <td>-0.104693</td>\n",
              "      <td>0.062760</td>\n",
              "      <td>0.060933</td>\n",
              "      <td>-0.005312</td>\n",
              "      <td>-0.014699</td>\n",
              "      <td>0.031377</td>\n",
              "      <td>0.071102</td>\n",
              "      <td>-0.049047</td>\n",
              "      <td>-0.125458</td>\n",
              "      <td>-0.094827</td>\n",
              "      <td>0.114646</td>\n",
              "      <td>0.088590</td>\n",
              "      <td>0.012954</td>\n",
              "      <td>0.049113</td>\n",
              "      <td>-0.108596</td>\n",
              "      <td>0.002915</td>\n",
              "      <td>0.039371</td>\n",
              "      <td>0.026193</td>\n",
              "      <td>-0.027983</td>\n",
              "      <td>0.038054</td>\n",
              "      <td>-0.067692</td>\n",
              "      <td>0.058649</td>\n",
              "      <td>0.140864</td>\n",
              "      <td>0.032995</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23508 rows Ã— 301 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2  ...       298       299  labels\n",
              "0     -0.050695 -0.013357 -0.008664  ... -0.025411  0.035197       0\n",
              "1     -0.003021  0.127523  0.022970  ...  0.129150  0.039032       0\n",
              "2     -0.029696  0.117454  0.070279  ...  0.084306  0.066426       0\n",
              "3     -0.034995  0.044120  0.062256  ...  0.183340 -0.034546       1\n",
              "4      0.015993  0.063070 -0.002374  ...  0.117784  0.017456       0\n",
              "...         ...       ...       ...  ...       ...       ...     ...\n",
              "23511 -0.037612 -0.003371 -0.043265  ...  0.091285  0.045650       1\n",
              "23512  0.003700  0.071014 -0.004820  ...  0.142891  0.104774       0\n",
              "23513 -0.051111  0.146917 -0.019682  ...  0.156669  0.086036       0\n",
              "23514 -0.108724  0.262695 -0.012207  ...  0.284668  0.115234       0\n",
              "23515 -0.116017  0.087541  0.000201  ...  0.140864  0.032995       1\n",
              "\n",
              "[23508 rows x 301 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnmk824TP6lI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0OjnxHLFgXD",
        "outputId": "a68aad26-263c-49b5-a80e-5f75a2f5279f"
      },
      "source": [
        "zerocount=0\n",
        "onecount=0\n",
        "for i in y_train:\n",
        "  if i == 0:\n",
        "    zerocount+=1\n",
        "  else:\n",
        "    onecount+=1\n",
        "print(\"no of negative sample in training class is:\",zerocount)\n",
        "print(\"no of positive sample in training class is:\",onecount) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no of negative sample in training class is: 13328\n",
            "no of positive sample in training class is: 5478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFJPtlVupcdN"
      },
      "source": [
        "from tensorflow .keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXiJblG43sCw"
      },
      "source": [
        "max_features = 300\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['observation'].values) "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEPe9ful364a"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True) "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4b1DcjA4AwE",
        "outputId": "9e62f207-993e-4fd9-dab4-245c637d3acd"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print(\"unique tokens - \"+str(len(word_index))) \n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('vocab_size - '+str(vocab_size)) "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique tokens - 16445\n",
            "vocab_size - 16446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oJqlzAc4HUf"
      },
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model: \n",
        "        embedding_vector = word2vec_model[word]\n",
        "        embedding_matrix[i] = embedding_vector "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsDcpPIj5Cyg"
      },
      "source": [
        "max_len=68"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D6VC6cc43a2"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len,\n",
        "                            trainable=False) "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q4gJM5T5IVI"
      },
      "source": [
        "y = docs_vectors['labels'].values\n",
        "x=docs_vectors.drop('labels' , axis=1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V-lhyts5daz"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=2021)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_yofmpf53v7",
        "outputId": "7428e29d-c9f3-4f1c-a455-fde91db81d86"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape) "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18806, 300)\n",
            "(18806,)\n",
            "(4702, 300)\n",
            "(4702,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU77UctDhrKF"
      },
      "source": [
        "rnn_model=Sequential()\n",
        "\n",
        "rnn_model.add(Embedding(300, 64, input_length=300))\n",
        "\n",
        "rnn_model.add(LSTM(192))\n",
        "\n",
        "rnn_model.add(Dense(1, activation='sigmoid'))  "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr4dEm_Ppt95",
        "outputId": "94de8b05-bc1b-410c-f5de-78ca42df8b73"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18806, 300)\n",
            "(18806,)\n",
            "(4702, 300)\n",
            "(4702,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fDPNI_dp9Rd"
      },
      "source": [
        "rnn_model.compile(optimizer='sgd', loss=\"binary_crossentropy\", metrics=['accuracy'])\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo5SVKz7pzIP",
        "outputId": "ead06bd4-a223-4d0e-cbf8-c8f77c76af8b"
      },
      "source": [
        "history=rnn_model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data = (x_test, y_test),\n",
        "    epochs = 20,batch_size=500)  "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "38/38 [==============================] - 213s 5s/step - loss: 0.6780 - accuracy: 0.7048 - val_loss: 0.6457 - val_accuracy: 0.7144\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 187s 5s/step - loss: 0.6408 - accuracy: 0.7079 - val_loss: 0.6222 - val_accuracy: 0.7144\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 181s 5s/step - loss: 0.6229 - accuracy: 0.7056 - val_loss: 0.6098 - val_accuracy: 0.7144\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 191s 5s/step - loss: 0.6111 - accuracy: 0.7094 - val_loss: 0.6038 - val_accuracy: 0.7144\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 184s 5s/step - loss: 0.6091 - accuracy: 0.7055 - val_loss: 0.6009 - val_accuracy: 0.7144\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 181s 5s/step - loss: 0.6059 - accuracy: 0.7073 - val_loss: 0.5995 - val_accuracy: 0.7144\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 186s 5s/step - loss: 0.6039 - accuracy: 0.7087 - val_loss: 0.5989 - val_accuracy: 0.7144\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 184s 5s/step - loss: 0.6023 - accuracy: 0.7101 - val_loss: 0.5986 - val_accuracy: 0.7144\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 188s 5s/step - loss: 0.6023 - accuracy: 0.7101 - val_loss: 0.5984 - val_accuracy: 0.7144\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 184s 5s/step - loss: 0.6007 - accuracy: 0.7117 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 184s 5s/step - loss: 0.6084 - accuracy: 0.7029 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 188s 5s/step - loss: 0.6027 - accuracy: 0.7094 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 184s 5s/step - loss: 0.6001 - accuracy: 0.7123 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 183s 5s/step - loss: 0.6058 - accuracy: 0.7059 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 180s 5s/step - loss: 0.5956 - accuracy: 0.7174 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 181s 5s/step - loss: 0.6065 - accuracy: 0.7051 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 184s 5s/step - loss: 0.6050 - accuracy: 0.7068 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 181s 5s/step - loss: 0.6046 - accuracy: 0.7073 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 180s 5s/step - loss: 0.6002 - accuracy: 0.7122 - val_loss: 0.5983 - val_accuracy: 0.7144\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 181s 5s/step - loss: 0.6057 - accuracy: 0.7060 - val_loss: 0.5983 - val_accuracy: 0.7144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Rxu73jiGp7mE",
        "outputId": "8ae91a71-1ee4-436f-af0c-9bf71dc4e6e7"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()  "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fes3pCvfZ_zE",
        "outputId": "83b130da-ffeb-46f7-f5af-facac9640370"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()  "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vzll-UbbTzq"
      },
      "source": [
        "import tensorflow as tf "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOzo1gTPccEj"
      },
      "source": [
        "rnn_model.compile(optimizer='sgd', loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.TrueNegatives(),tf.keras.metrics.TruePositives(),tf.keras.metrics.FalsePositives(),tf.keras.metrics.FalseNegatives()])\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iKiPEiyDc4zU",
        "outputId": "23b76383-b732-4c41-b3cc-184db1de39de"
      },
      "source": [
        "rnn_model.fit(\n",
        "    x_train,y_train,\n",
        "    validation_data = (x_test,y_test),\n",
        "    epochs = 3,batch_size=500)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "38/38 [==============================] - 218s 5s/step - loss: 0.5984 - true_negatives: 3745.5722 - true_positives: 0.0000e+00 - false_positives: 0.0000e+00 - false_negatives: 1497.7557 - val_loss: 0.5983 - val_true_negatives: 15268.9004 - val_true_positives: 0.0000e+00 - val_false_positives: 0.0000e+00 - val_false_negatives: 6257.2998\n",
            "Epoch 2/3\n",
            "14/38 [==========>...................] - ETA: 1:46 - loss: 0.6025 - true_negatives: 18196.7948 - true_positives: 0.0000e+00 - false_positives: 0.0000e+00 - false_negatives: 7436.2050"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-b64b01bff864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     epochs = 3,batch_size=500)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}